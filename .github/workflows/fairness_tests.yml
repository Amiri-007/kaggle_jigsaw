name: Fairness Metrics CI

on:
  push:
    branches: [ main, master ]
    paths:
      - 'src/metrics_v2.py'
      - 'src/vis_utils.py'
      - 'notebooks/03_bias_evaluation.py'
      - 'tests/test_metrics_v2.py'
  pull_request:
    branches: [ main, master ]
    paths:
      - 'src/metrics_v2.py'
      - 'src/vis_utils.py'
      - 'notebooks/03_bias_evaluation.py'
      - 'tests/test_metrics_v2.py'

jobs:
  test:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest matplotlib pandas numpy scikit-learn plotly nbconvert jupyter ipykernel
        pip install -r requirements.txt
    
    - name: Run pytest
      run: |
        pytest tests/test_metrics_v2.py -v
    
    - name: Convert notebook to executable and run
      run: |
        # Create sample data for testing
        mkdir -p data
        mkdir -p output/preds
        mkdir -p results
        
        # Create synthetic data for notebook testing
        python -c "
        import pandas as pd
        import numpy as np
        
        # Create synthetic ground truth
        np.random.seed(42)
        n_samples = 1000
        data = {
            'id': range(1, n_samples + 1),
            'comment_text': ['Text ' + str(i) for i in range(1, n_samples + 1)],
            'target': np.random.randint(0, 2, n_samples),
        }
        
        # Add identity columns
        for identity in ['male', 'female', 'black', 'white', 'muslim', 'christian']:
            data[identity] = np.random.randint(0, 2, n_samples)
        
        # Save as CSV
        pd.DataFrame(data).to_csv('data/train.csv', index=False)
        
        # Create model predictions
        preds = {
            'id': range(1, n_samples + 1),
            'prediction': np.clip(np.random.normal(data['target'], 0.3), 0, 1)
        }
        pd.DataFrame(preds).to_csv('output/preds/tfidf_logreg.csv', index=False)
        "
        
        # Convert Python script to notebook and execute
        jupyter nbconvert --execute --to notebook notebooks/03_bias_evaluation.py
    
    - name: Upload test artifacts
      uses: actions/upload-artifact@v3
      with:
        name: test-results
        path: |
          results/
          output/figures/
          notebooks/03_bias_evaluation.nbconvert.ipynb 