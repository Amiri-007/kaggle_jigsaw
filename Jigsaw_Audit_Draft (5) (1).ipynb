{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9b846d92",
      "metadata": {
        "id": "9b846d92"
      },
      "source": [
        "# Jigsaw Unintended Bias Audit – Draft Notebook\n",
        "\n",
        "*Responsible Data Science, Spring 2025*\n",
        "Michael and Julius\n",
        "Following is written in collabration with AI, almost all documentation is auto generated while some are handwritten, the co-pilot auto-gens sufficed. And some of the code is also AI assisted via co-pilot. \n",
        "\n",
        "This Colab‑friendly notebook supports the **draft report**. It:\n",
        "1. Installs all needed libraries (Kaggle API, transformers …).\n",
        "2. Downloads the competition data via the Kaggle API.\n",
        "3. Performs a lightweight exploratory analysis.\n",
        "4. Trains a quick TF‑IDF + LogReg baseline and evaluates the competition AUC metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8a83752",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8a83752",
        "outputId": "af853e1c-7bae-4d29-ea0a-08a7ac9182db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Libraries installed (Colab's built‑in PyTorch is intact)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# # ---- Environment bootstrap -----------------------------\n",
        "# !pip -q install --upgrade kaggle==1.6.8 datasets transformers evaluate scikit-learn textstat pyarrow --no-warn-script-location\n",
        "# import os, json, pathlib, subprocess, textwrap, zipfile, shutil, random, numpy as np, pandas as pd\n",
        "# print('✓ Libraries installed')\n",
        "\n",
        "# ---- Environment bootstrap (Colab‑safe) -------------------\n",
        "!pip -q install --upgrade kaggle datasets transformers evaluate textstat pyarrow --no-warn-script-location\n",
        "import os, json, pathlib, subprocess, random, numpy as np, pandas as pd\n",
        "print(\"✓ Libraries installed (Colab's built‑in PyTorch is intact)\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xgbdMqK6KL9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgbdMqK6KL9b",
        "outputId": "c2804baf-9fc5-4477-e2db-b26448d37a00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 757.3/757.3 MB 1.5 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.0/7.0 MB 31.6 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.8/43.8 kB 1.8 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.6/84.6 kB 4.0 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.0/85.0 kB 7.8 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.6/57.6 kB 5.2 MB/s eta 0:00:00\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.6/78.6 kB 7.7 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.1/9.1 MB 87.3 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 265.7/265.7 kB 24.2 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 251.6/251.6 kB 22.6 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 542.0/542.0 kB 41.5 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.1/84.1 kB 8.4 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 74.8 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.3/78.3 kB 7.7 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 163.8/163.8 kB 15.6 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.1/12.1 MB 121.1 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 410.6/410.6 MB 2.4 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.1/14.1 MB 114.4 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.7/23.7 MB 94.5 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.6/823.6 kB 54.1 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 731.7/731.7 MB 1.6 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.6/121.6 MB 18.7 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.5/56.5 MB 39.7 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.2/124.2 MB 18.1 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 196.0/196.0 MB 5.7 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 166.0/166.0 MB 13.8 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 99.1/99.1 kB 9.2 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 167.9/167.9 MB 5.5 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 86.7 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 231.9/231.9 kB 18.4 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.6/84.6 kB 8.2 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 152.8/152.8 kB 13.3 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.5/49.5 kB 4.3 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 109.0/109.0 kB 10.4 MB/s eta 0:00:00\n",
            "✓ stack ready → torch 2.2.1+cu121, transformers 4.41.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2023.6.0 which is incompatible.\n",
            "textblob 0.19.0 requires nltk>=3.9, but you have nltk 3.8.1 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.1+cu121 which is incompatible.\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<stdin>\", line 1, in <module>\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1477, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 9, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "\r0it [00:00, ?it/s]\r0it [00:00, ?it/s]\n",
            "2025-04-17 09:56:12.422251: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744883772.444494    8690 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744883772.451414    8690 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "# clean start – uninstall incompatible HF fragments\n",
        "pip -q uninstall -y transformers accelerate peft datasets evaluate -qq || true\n",
        "\n",
        "# single pinned stack tested on Colab (A100 & T4, CUDA 12.1)\n",
        "pip -q install --upgrade --no-warn-script-location \\\n",
        "  \"torch==2.2.1+cu121\" \"torchvision==0.17.1+cu121\" \\\n",
        "     -f https://download.pytorch.org/whl/cu121/torch_stable.html \\\n",
        "  transformers==4.41.0 \\\n",
        "  accelerate==0.25.0 \\\n",
        "  peft==0.11.1 \\\n",
        "  datasets==2.19.1 \\\n",
        "  evaluate==0.4.2 \\\n",
        "  kaggle==1.6.8 optuna==0.13.0 nltk==3.8.1 attrdict==2.0.1 \\\n",
        "  tqdm==4.66.2 fsspec==2023.6.0 scikit-learn==1.4.2\n",
        "\n",
        "python - <<'PY'\n",
        "import torch, transformers, accelerate, peft, datasets, evaluate\n",
        "print(f\"✓ stack ready → torch {torch.__version__}, transformers {transformers.__version__}\")\n",
        "PY\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c45f2007",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "c45f2007",
        "outputId": "65e23e68-ba91-4825-9380-9db5775ab641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upload kaggle.json...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-70462ea9-d5a0-4fc4-8ab4-310f08992b81\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-70462ea9-d5a0-4fc4-8ab4-310f08992b81\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n",
            "- path is now set to: /content/data\n",
            "✓ Kaggle API configured\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ----  Kaggle authentication ------------------------------\n",
        "from google.colab import files\n",
        "import shutil # import the shutil module\n",
        "home = pathlib.Path.home()\n",
        "kaggle_path = home/'.kaggle'\n",
        "kaggle_path.mkdir(exist_ok=True)\n",
        "if not (kaggle_path/'kaggle.json').exists():\n",
        "    print(\"Upload kaggle.json...\")\n",
        "    uploaded = files.upload()\n",
        "    for fn in uploaded.keys():\n",
        "        shutil.move(fn, kaggle_path/'kaggle.json')\n",
        "        os.chmod(kaggle_path/'kaggle.json', 0o600)\n",
        "!kaggle config set -n path -v /content/data\n",
        "print('✓ Kaggle API configured')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c38a56f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c38a56f",
        "outputId": "7be32f01-cf2c-48a3-e8b5-f8e280414115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading jigsaw-unintended-bias-in-toxicity-classification.zip to /content/data\n",
            " 93% 676M/723M [00:00<00:00, 1.16GB/s]\n",
            "100% 723M/723M [00:00<00:00, 1.17GB/s]\n",
            "Files: ['sample_submission.csv', 'identity_individual_annotations.csv', 'train.csv', 'all_data.csv', 'test.csv', 'test_public_expanded.csv', 'jigsaw-unintended-bias-in-toxicity-classification.zip', 'test_private_expanded.csv', 'toxicity_individual_annotations.csv']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ----  Download data --------------------------------------\n",
        "COMP = \"jigsaw-unintended-bias-in-toxicity-classification\"\n",
        "!kaggle competitions download -c $COMP -p /content/data --force\n",
        "!unzip -q /content/data/$COMP*.zip -d /content/data\n",
        "print('Files:', os.listdir('/content/data')[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10d95848",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "10d95848",
        "outputId": "c3d7c847-53f4-4303-e864-1ac528a42934"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(200000, 45)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-77ccc5d4-dedd-4988-b9d9-75d18b8fc065\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>severe_toxicity</th>\n",
              "      <th>obscene</th>\n",
              "      <th>identity_attack</th>\n",
              "      <th>insult</th>\n",
              "      <th>threat</th>\n",
              "      <th>asian</th>\n",
              "      <th>atheist</th>\n",
              "      <th>...</th>\n",
              "      <th>article_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>funny</th>\n",
              "      <th>wow</th>\n",
              "      <th>sad</th>\n",
              "      <th>likes</th>\n",
              "      <th>disagree</th>\n",
              "      <th>sexual_explicit</th>\n",
              "      <th>identity_annotator_count</th>\n",
              "      <th>toxicity_annotator_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59848</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>2006</td>\n",
              "      <td>rejected</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>59849</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Thank you!! This would make my life a lot less...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>2006</td>\n",
              "      <td>rejected</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>59852</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>This is such an urgent design problem; kudos t...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>2006</td>\n",
              "      <td>rejected</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>59855</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Is this something I'll be able to install on m...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>2006</td>\n",
              "      <td>rejected</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59856</td>\n",
              "      <td>0.893617</td>\n",
              "      <td>haha you guys are a bunch of losers.</td>\n",
              "      <td>0.021277</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.021277</td>\n",
              "      <td>0.87234</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2006</td>\n",
              "      <td>rejected</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 45 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77ccc5d4-dedd-4988-b9d9-75d18b8fc065')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-77ccc5d4-dedd-4988-b9d9-75d18b8fc065 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-77ccc5d4-dedd-4988-b9d9-75d18b8fc065');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a4f55861-96a1-4f68-88fb-8e7dd53ab2f7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a4f55861-96a1-4f68-88fb-8e7dd53ab2f7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a4f55861-96a1-4f68-88fb-8e7dd53ab2f7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      id    target                                       comment_text  \\\n",
              "0  59848  0.000000  This is so cool. It's like, 'would you want yo...   \n",
              "1  59849  0.000000  Thank you!! This would make my life a lot less...   \n",
              "2  59852  0.000000  This is such an urgent design problem; kudos t...   \n",
              "3  59855  0.000000  Is this something I'll be able to install on m...   \n",
              "4  59856  0.893617               haha you guys are a bunch of losers.   \n",
              "\n",
              "   severe_toxicity  obscene  identity_attack   insult  threat  asian  atheist  \\\n",
              "0         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
              "1         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
              "2         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
              "3         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
              "4         0.021277      0.0         0.021277  0.87234     0.0    0.0      0.0   \n",
              "\n",
              "   ...  article_id    rating  funny  wow  sad  likes  disagree  \\\n",
              "0  ...        2006  rejected      0    0    0      0         0   \n",
              "1  ...        2006  rejected      0    0    0      0         0   \n",
              "2  ...        2006  rejected      0    0    0      0         0   \n",
              "3  ...        2006  rejected      0    0    0      0         0   \n",
              "4  ...        2006  rejected      0    0    0      1         0   \n",
              "\n",
              "   sexual_explicit  identity_annotator_count  toxicity_annotator_count  \n",
              "0              0.0                         0                         4  \n",
              "1              0.0                         0                         4  \n",
              "2              0.0                         0                         4  \n",
              "3              0.0                         0                         4  \n",
              "4              0.0                         4                        47  \n",
              "\n",
              "[5 rows x 45 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              target\n",
            "count  200000.000000\n",
            "mean        0.098020\n",
            "std         0.194695\n",
            "min         0.000000\n",
            "25%         0.000000\n",
            "50%         0.000000\n",
            "75%         0.166667\n",
            "max         1.000000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ---- Load dataset & quick EDA ---------------------------\n",
        "import pandas as pd, pyarrow.parquet as pq, numpy as np\n",
        "train_csv = '/content/data/train.csv'\n",
        "df = pd.read_csv(train_csv, nrows=200_000)  # sample for Colab RAM\n",
        "print(df.shape)\n",
        "display(df.head())\n",
        "print(df[['target']].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f0e1ffc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f0e1ffc",
        "outputId": "aabbc43a-bd56-447e-e0f4-eec94748780a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation ROC‑AUC: 0.9322\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ---- Baseline TF‑IDF + Logistic Regression --------------\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(df['comment_text'].fillna(' '),\n",
        "                                                     df['target']>=0.5, test_size=0.2, random_state=42)\n",
        "vectorizer = TfidfVectorizer(max_features=100_000, ngram_range=(1,2), stop_words='english')\n",
        "Xtr = vectorizer.fit_transform(X_train)\n",
        "Xva = vectorizer.transform(X_valid)\n",
        "clf = LogisticRegression(max_iter=1000, n_jobs=-1)\n",
        "clf.fit(Xtr, y_train)\n",
        "pred = clf.predict_proba(Xva)[:,1]\n",
        "auc = roc_auc_score(y_valid, pred)\n",
        "print(f\"Validation ROC‑AUC: {auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "p3gPtBSZP9uK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "590d87e12f0e46bb9e5c207aac830576",
            "ed580d7893ef44798ad3a37408a7082a",
            "b95292599cac451387e3431467f8ee04",
            "d0278eaa65d34b71b981b62cd3fea9b0",
            "729f51aa311344caa696dc88472b9d36",
            "bf312655900e4218b6a4d16eeb712dbc",
            "3a07d42644c84b87b51aa95082798607",
            "e489b70415cc4be0847da45bbff1bd22",
            "50ee56b60c3d4102bb01c283e9b9d687",
            "fb63047633da4b19ae7b54a0e9f73dcf",
            "b1102e7bd07f4e668ac0691c5e1cb6c9"
          ]
        },
        "id": "p3gPtBSZP9uK",
        "outputId": "1877e5ba-7391-4b50-f245-033a4025521f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "590d87e12f0e46bb9e5c207aac830576",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/40000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ bert_valid_ds Dataset({\n",
            "    features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
            "    num_rows: 40000\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# --- tokeniser & HF validation Dataset (needed once) ----------\n",
        "from transformers import AutoTokenizer\n",
        "from datasets      import Dataset\n",
        "\n",
        "tok_fn = lambda s: tok(\n",
        "    s[\"comment_text\"],\n",
        "    truncation=True,\n",
        "    padding=\"max_length\",\n",
        "    max_length=220,\n",
        ")\n",
        "\n",
        "# Build a HF Dataset that lines up with X_valid / y_valid\n",
        "bert_valid_ds = Dataset.from_pandas(\n",
        "    pd.DataFrame({\"comment_text\": X_valid.reset_index(drop=True)})\n",
        ").map(tok_fn, batched=True, remove_columns=[\"comment_text\"]).with_format(\"torch\")\n",
        "\n",
        "print(\"✓ bert_valid_ds\", bert_valid_ds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "iMEv1HGtM9--",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMEv1HGtM9--",
        "outputId": "81c98f2f-c87b-4ce4-9eaf-937050bf8b16"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ BERT on GPU  |  dtype=torch.bfloat16\n"
          ]
        }
      ],
      "source": [
        "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
        "                          pipeline, BitsAndBytesConfig)\n",
        "import torch, math, numpy as np\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "dtype  = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
        "\n",
        "tok   = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert  = AutoModelForSequenceClassification.from_pretrained(\n",
        "            \"bert-base-uncased\",\n",
        "            num_labels=1, problem_type=\"single_label_regression\",\n",
        "            torch_dtype=dtype, low_cpu_mem_usage=True).to(device)\n",
        "\n",
        "pipe  = pipeline(\"text-classification\",\n",
        "                 model=bert, tokenizer=tok,\n",
        "                 function_to_apply=\"sigmoid\",\n",
        "                 batch_size=64,            # GPU‑friendly\n",
        "                 device=device)\n",
        "\n",
        "print(f\"✓ BERT on {'GPU' if device==0 else 'CPU'}  |  dtype={dtype}\")\n",
        "\n",
        "pred_bert = np.array([p[\"score\"] for p in pipe(list(X_valid))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "r-cPUmeXrePe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140,
          "referenced_widgets": [
            "090170b0b333417082d30bf80406ffd8",
            "87dd9c03a81440f4a214760878d1215e",
            "3fc60ee69a4c45ff9b33f275b9273af7",
            "cfebcc82a5f14656adc910d54d1f5580",
            "95ddc737d97a4eee9954ba4d8036314c",
            "d8d2ab8769c842c68f2c6f6f761ff7e6",
            "d0b639095d3b49fa80ee77815ca5a064",
            "c9676ea62ba74238b26b1d02c68f2a3e",
            "75db9d06bf674e3c93912068a5cd276a",
            "e0a1209668e34be2bbe6f48455c366be",
            "fba2ce85588e454eb8f2f36756f723c9"
          ]
        },
        "id": "r-cPUmeXrePe",
        "outputId": "03dee0e2-2933-446b-b82a-2e6e8fd9c5df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ BERT pipeline  •  device=GPU  •  dtype=torch.bfloat16\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "090170b0b333417082d30bf80406ffd8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "BERT batches:   0%|          | 0/625 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ df_valid saved – shape (40000, 17) | pred_tfidf (40000,) | pred_bert (40000,)\n"
          ]
        }
      ],
      "source": [
        "# ── Collect predictions & build df_valid ────────────────────────────────\n",
        "import numpy as np, pandas as pd, pathlib, json, torch, math\n",
        "from tqdm.auto import tqdm\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "\n",
        "# ---------- 1) TF‑IDF predictions (already trained) --------------------\n",
        "pred_tfidf = clf.predict_proba(Xva)[:, 1]          # shape (|X_valid|,)\n",
        "\n",
        "# ---------- 2) Fast GPU BERT inference ---------------------------------\n",
        "DEVICE = 0 if torch.cuda.is_available() else -1\n",
        "DTYPE  = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
        "torch.backends.cuda.matmul.allow_tf32 = True       # +speed on A100/T4\n",
        "\n",
        "tok  = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert = AutoModelForSequenceClassification.from_pretrained(\n",
        "            \"bert-base-uncased\",\n",
        "            num_labels=1,\n",
        "            problem_type=\"single_label_regression\",\n",
        "            torch_dtype=DTYPE,\n",
        "            low_cpu_mem_usage=True\n",
        "        ).to(DEVICE)\n",
        "\n",
        "pipe = pipeline(\n",
        "    task              = \"text-classification\",\n",
        "    model             = bert,\n",
        "    tokenizer         = tok,\n",
        "    function_to_apply = \"sigmoid\",\n",
        "    device            = DEVICE,\n",
        "    batch_size        = 64\n",
        ")\n",
        "\n",
        "print(f\"✓ BERT pipeline  •  device={'GPU' if DEVICE==0 else 'CPU'}  •  dtype={DTYPE}\")\n",
        "\n",
        "# ensure we hand the pipeline *lists of str*, never NumPy arrays\n",
        "X_valid_list = X_valid.fillna(\" \").astype(str).tolist()\n",
        "\n",
        "pred_bert = []\n",
        "for i in tqdm(range(0, len(X_valid_list), 64), desc=\"BERT batches\"):\n",
        "    batch = X_valid_list[i : i+64]           # Python list of  ≤64 strings\n",
        "    scores = pipe(batch)                     # [{\"label\":\"POS\",\"score\":…}, …]\n",
        "    pred_bert.extend([p[\"score\"] for p in scores])\n",
        "\n",
        "pred_bert = np.asarray(pred_bert, dtype=np.float32)   # shape (|X_valid|,)\n",
        "assert len(pred_bert) == len(X_valid_list), \"length mismatch!\"\n",
        "\n",
        "# ---------- 3) build & save df_valid -----------------------------------\n",
        "IDENTITY_COLS = [\"male\",\"female\",\"black\",\"white\",\"asian\",\"christian\",\n",
        "                 \"jewish\",\"muslim\",\"hindu\",\"buddhist\",\"atheist\",\"lgbtq\",\n",
        "                 \"transgender\"]\n",
        "\n",
        "df_valid = pd.DataFrame({\n",
        "    \"comment_text\": X_valid_list,\n",
        "    \"target\":       y_valid.reset_index(drop=True),\n",
        "    \"pred_tfidf\":   pred_tfidf,\n",
        "    \"pred_bert\":    pred_bert,\n",
        "    **{c: 0. for c in IDENTITY_COLS}          # dummy identity columns\n",
        "})\n",
        "\n",
        "pathlib.Path(\"logs\").mkdir(exist_ok=True)\n",
        "df_valid.to_parquet(\"logs/baseline_valid.parquet\", index=False)\n",
        "\n",
        "print(\"✓ df_valid saved – shape\", df_valid.shape,\n",
        "      \"| pred_tfidf\", pred_tfidf.shape,\n",
        "      \"| pred_bert\",  pred_bert.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "ae938147",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae938147",
        "outputId": "1bfcbe55-dc4f-4811-a23a-8681fa76cc55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Artifacts saved to /content/artifacts\n"
          ]
        }
      ],
      "source": [
        "# ---- Save artifacts -------------------------------------\n",
        "out_dir = pathlib.Path('/content/artifacts')\n",
        "out_dir.mkdir(exist_ok=True)\n",
        "df_valid = pd.DataFrame({'pred': pred, 'target': y_valid.reset_index(drop=True)})\n",
        "df_valid.to_parquet(out_dir/'baseline_valid.parquet', index=False)\n",
        "vectorizer_path = out_dir/'tfidf.pkl'\n",
        "clf_path = out_dir/'logreg.pkl'\n",
        "import pickle, gzip\n",
        "with gzip.open(vectorizer_path, 'wb') as f: pickle.dump(vectorizer, f)\n",
        "with gzip.open(clf_path, 'wb') as f: pickle.dump(clf, f)\n",
        "print('Artifacts saved to', out_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "DJR5XM5sp2a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJR5XM5sp2a4",
        "outputId": "13c0caaa-7a8f-450d-d673-e0279a6e6986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ feature_profile.tex saved\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import pearsonr\n",
        "from io import StringIO\n",
        "\n",
        "profile = []\n",
        "for col in df.columns:\n",
        "    series = df[col]\n",
        "    dtype = series.dtype\n",
        "    miss = series.isna().mean()*100\n",
        "    if pd.api.types.is_numeric_dtype(series):\n",
        "        rng = (series.min(), series.max())\n",
        "        profile.append((col, dtype.name, miss, f\"{rng[0]:.2f} – {rng[1]:.2f}\"))\n",
        "    else:\n",
        "        uniq = series.nunique()\n",
        "        profile.append((col, dtype.name, miss, f\"{uniq} unique\"))\n",
        "\n",
        "tex_table = StringIO()\n",
        "tex_table.write(\"\\\\begin{tabular}{llll}\\\\toprule\\n\")\n",
        "tex_table.write(\"Feature & Dtype & Missing\\\\,(\\\\%) & Range / Card.\\\\\\\\\\\\midrule\\n\")\n",
        "for row in profile:\n",
        "    tex_table.write(f\"{row[0]} & {row[1]} & {row[2]:.2f} & {row[3]}\\\\\\\\\\n\")\n",
        "tex_table.write(\"\\\\bottomrule\\\\end{tabular}\")\n",
        "with open(\"feature_profile.tex\", \"w\") as f: f.write(tex_table.getvalue())\n",
        "print(\"✓ feature_profile.tex saved\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hngHKeq7Qskj",
      "metadata": {
        "id": "hngHKeq7Qskj"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "KZ0TE1FjPPTP",
      "metadata": {
        "id": "KZ0TE1FjPPTP"
      },
      "outputs": [],
      "source": [
        "df_valid = pd.DataFrame({\n",
        "    \"comment_text\": X_valid.reset_index(drop=True),   # same ordering\n",
        "    \"target\":       y_valid.reset_index(drop=True),\n",
        "    **{c: 0. for c in IDENTITY_COLS},                 # dummy identity flags\n",
        "    \"pred_tfidf\":   pred_tfidf,\n",
        "    \"pred_bert\":    pred_bert\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FUk1C3wnp8dH",
      "metadata": {
        "id": "FUk1C3wnp8dH"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x = np.arange(len(IDENTITY_COLS))\n",
        "width = 0.35\n",
        "plt.bar(x - width/2, [metrics[\"tfidf\"][\"subgroup\"][c] for c in IDENTITY_COLS], width,\n",
        "        label=\"TF–IDF\")\n",
        "plt.bar(x + width/2, [metrics[\"bert\"][\"subgroup\"][c]  for c in IDENTITY_COLS], width,\n",
        "        label=\"BERT\")\n",
        "plt.axhline(metrics[\"tfidf\"][\"overall\"], linestyle=\"--\")\n",
        "plt.axhline(metrics[\"bert\"][\"overall\"], linestyle=\"--\")\n",
        "plt.xticks(x, IDENTITY_COLS, rotation=90)\n",
        "plt.ylabel(\"AUC\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"figs/auc_barplot.pdf\")\n",
        "print(\"✓ Figure saved to figs/auc_barplot.pdf\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "090170b0b333417082d30bf80406ffd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87dd9c03a81440f4a214760878d1215e",
              "IPY_MODEL_3fc60ee69a4c45ff9b33f275b9273af7",
              "IPY_MODEL_cfebcc82a5f14656adc910d54d1f5580"
            ],
            "layout": "IPY_MODEL_95ddc737d97a4eee9954ba4d8036314c"
          }
        },
        "3a07d42644c84b87b51aa95082798607": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3fc60ee69a4c45ff9b33f275b9273af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9676ea62ba74238b26b1d02c68f2a3e",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75db9d06bf674e3c93912068a5cd276a",
            "value": 625
          }
        },
        "50ee56b60c3d4102bb01c283e9b9d687": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "590d87e12f0e46bb9e5c207aac830576": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed580d7893ef44798ad3a37408a7082a",
              "IPY_MODEL_b95292599cac451387e3431467f8ee04",
              "IPY_MODEL_d0278eaa65d34b71b981b62cd3fea9b0"
            ],
            "layout": "IPY_MODEL_729f51aa311344caa696dc88472b9d36"
          }
        },
        "729f51aa311344caa696dc88472b9d36": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75db9d06bf674e3c93912068a5cd276a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87dd9c03a81440f4a214760878d1215e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8d2ab8769c842c68f2c6f6f761ff7e6",
            "placeholder": "​",
            "style": "IPY_MODEL_d0b639095d3b49fa80ee77815ca5a064",
            "value": "BERT batches: 100%"
          }
        },
        "95ddc737d97a4eee9954ba4d8036314c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1102e7bd07f4e668ac0691c5e1cb6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b95292599cac451387e3431467f8ee04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e489b70415cc4be0847da45bbff1bd22",
            "max": 40000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50ee56b60c3d4102bb01c283e9b9d687",
            "value": 40000
          }
        },
        "bf312655900e4218b6a4d16eeb712dbc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9676ea62ba74238b26b1d02c68f2a3e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfebcc82a5f14656adc910d54d1f5580": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0a1209668e34be2bbe6f48455c366be",
            "placeholder": "​",
            "style": "IPY_MODEL_fba2ce85588e454eb8f2f36756f723c9",
            "value": " 625/625 [00:33&lt;00:00, 18.41it/s]"
          }
        },
        "d0278eaa65d34b71b981b62cd3fea9b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb63047633da4b19ae7b54a0e9f73dcf",
            "placeholder": "​",
            "style": "IPY_MODEL_b1102e7bd07f4e668ac0691c5e1cb6c9",
            "value": " 40000/40000 [00:14&lt;00:00, 2857.59 examples/s]"
          }
        },
        "d0b639095d3b49fa80ee77815ca5a064": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8d2ab8769c842c68f2c6f6f761ff7e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0a1209668e34be2bbe6f48455c366be": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e489b70415cc4be0847da45bbff1bd22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed580d7893ef44798ad3a37408a7082a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf312655900e4218b6a4d16eeb712dbc",
            "placeholder": "​",
            "style": "IPY_MODEL_3a07d42644c84b87b51aa95082798607",
            "value": "Map: 100%"
          }
        },
        "fb63047633da4b19ae7b54a0e9f73dcf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fba2ce85588e454eb8f2f36756f723c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
